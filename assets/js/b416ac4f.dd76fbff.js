"use strict";(self.webpackChunkmapillary_js_doc=self.webpackChunkmapillary_js_doc||[]).push([[6578],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return h}});var r=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,r,i=function(e,t){if(null==e)return{};var a,r,i={},n=Object.keys(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var l=r.createContext({}),p=function(e){var t=r.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=p(e.components);return r.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var a=e.components,i=e.mdxType,n=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),m=p(a),h=i,u=m["".concat(l,".").concat(h)]||m[h]||d[h]||n;return a?r.createElement(u,o(o({ref:t},c),{},{components:a})):r.createElement(u,o({ref:t},c))}));function h(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var n=a.length,o=new Array(n);o[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,o[1]=s;for(var p=2;p<n;p++)o[p]=a[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,a)}m.displayName="MDXCreateElement"},3640:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return o},contentTitle:function(){return s},metadata:function(){return l},toc:function(){return p},default:function(){return d}});var r=a(2122),i=a(9756),n=(a(7294),a(3905)),o={id:"glossary",title:"Glossary"},s=void 0,l={unversionedId:"intro/glossary",id:"intro/glossary",isDocsHomePage:!1,title:"Glossary",description:"This glossary provides a non-exhaustive list of terms used in the MapillaryJS documentation and codebase.",source:"@site/docs/intro/glossary.md",sourceDirName:"intro",slug:"/intro/glossary",permalink:"/mapillary-js/docs/intro/glossary",editUrl:"https://github.com/mapillary/mapillary-js/edit/main/doc/docs/intro/glossary.md",tags:[],version:"current",frontMatter:{id:"glossary",title:"Glossary"},sidebar:"docs",previous:{title:"Try MapillaryJS",permalink:"/mapillary-js/docs/intro/try"},next:{title:"Guide",permalink:"/mapillary-js/docs/main/guide"}},p=[{value:"Camera Calibration",id:"camera-calibration",children:[]},{value:"Camera Capture",id:"camera-capture",children:[]},{value:"Camera Controls",id:"camera-controls",children:[]},{value:"Camera Frame",id:"camera-frame",children:[]},{value:"Custom Renderer",id:"custom-renderer",children:[]},{value:"Data Provider",id:"data-provider",children:[]},{value:"Distortion",id:"distortion",children:[{value:"Distort",id:"distort",children:[]},{value:"Undistort",id:"undistort",children:[]}]},{value:"Geographic Anchor",id:"geographic-anchor",children:[]},{value:"Image",id:"image",children:[]},{value:"Image Tile",id:"image-tile",children:[]},{value:"Street Imagery Map",id:"street-imagery-map",children:[]},{value:"Projection",id:"projection",children:[{value:"Types",id:"types",children:[]}]},{value:"Unprojection",id:"unprojection",children:[]},{value:"Viewer",id:"viewer",children:[]},{value:"Space",id:"space",children:[{value:"Real 3D World",id:"real-3d-world",children:[]},{value:"Distorted 2D Projection",id:"distorted-2d-projection",children:[]},{value:"Undistorted 3D Space",id:"undistorted-3d-space",children:[]}]}],c={toc:p};function d(e){var t=e.components,a=(0,i.Z)(e,["components"]);return(0,n.kt)("wrapper",(0,r.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("p",null,"This glossary provides a non-exhaustive list of terms used in the MapillaryJS documentation and codebase."),(0,n.kt)("h2",{id:"camera-calibration"},"Camera Calibration"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Camera_resectioning"},"Camera calibration")," is the process of ",(0,n.kt)("a",{parentName:"p",href:"https://www.mathworks.com/help/vision/ug/camera-calibration.html"},"estimating the parameters")," of a camera model to approximate the physical (or virtual) camera that captured a set images."),(0,n.kt)("h2",{id:"camera-capture"},"Camera Capture"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Image#Still_or_moving"},"Still image")," captured by a ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Camera"},"camera"),". It can be photographs but also frames extracted from a video. The still images are used as background textures in the ",(0,n.kt)("a",{parentName:"p",href:"#street-imagery-map"},"street imagery map"),"."),(0,n.kt)("h2",{id:"camera-controls"},"Camera Controls"),(0,n.kt)("p",null,"Specifies different modes for how the ",(0,n.kt)("a",{parentName:"p",href:"#viewer"},"viewer"),"'s virtual camera is controlled through pointer, keyboard or other modes of input. Custom camera controls allow the API user to freely move the viewer's camera and define the ","[camera projection]"," used."),(0,n.kt)("h2",{id:"camera-frame"},"Camera Frame"),(0,n.kt)("p",null,"A three-dimensional visual representation of a the camera used to capture a still image. Different projection types and camera parameters can be visualized in different ways to indicate the underlying camera model and parameters."),(0,n.kt)("h2",{id:"custom-renderer"},"Custom Renderer"),(0,n.kt)("p",null,"Can be implemented to superimpose any geo-anchored 3D content on the street-level imagery. You can render 3D models of any format and create animations in the undistorted 3D space of MapillaryJS. You can even create 3D content editor functionality directly in the viewer."),(0,n.kt)("h2",{id:"data-provider"},"Data Provider"),(0,n.kt)("p",null,"Write a data provider to render your own 3D reconstruction data of any format in MapillaryJS. You can use the data provider API to provide data in the MapillaryJS ent format. The data can come from anywhere, e.g. service APIs, JSON files, or even be generated procedurally in the browser."),(0,n.kt)("h2",{id:"distortion"},"Distortion"),(0,n.kt)("p",null,(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Distortion_(optics)"},"Distortion")," is a deviation from ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Rectilinear_lens"},"rectilinear projection"),"; a projection in which straight lines in a scene remain straight in an image."),(0,n.kt)("h3",{id:"distort"},"Distort"),(0,n.kt)("p",null,"When a scene of the ",(0,n.kt)("a",{parentName:"p",href:"#real-3d-world"},"real 3D world")," is captured with cameras, it is projected onto 2D textures. Depending on the camera, this process can introduce some errors. One of them is radial distortion, which causes straight lines in the real world to look bent in the 2D image."),(0,n.kt)("h3",{id:"undistort"},"Undistort"),(0,n.kt)("p",null,"Using ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Computer_vision"},"computer vision"),", it is possible to ",(0,n.kt)("a",{parentName:"p",href:"https://docs.opencv.org/3.4/dc/dbb/tutorial_py_calibration.html"},"compensate for radial distortion"),"."),(0,n.kt)("p",null,"Radial distortion is different for every camera. To reconstruct a good 3D model from 2D images we need to determine the distortion. Mapillary uses ",(0,n.kt)("a",{parentName:"p",href:"https://github.com/mapillary/opensfm"},"OpenSfM")," as the technology for 3D reconstruction, which calculates radial distortion parameters during the process. Using the calibration parameters, image textures can be undistorted on the fly in MapillaryJS. The result is that lines that are straight in the real world will now also be straightened in MapillaryJS. Another effect is that image borders are not straight anymore after undistorting the image."),(0,n.kt)("p",null,"Besides making images look more realistic, undistortion also has several other benefits. In general, image pixels are now correctly related to 3D positions in the viewer. This results in better alignment between the pixels of different images and, therefore, smoother transitions and less artifacts when navigating between images."),(0,n.kt)("h2",{id:"geographic-anchor"},"Geographic Anchor"),(0,n.kt)("p",null,"A geographic anchor identifies a geographic location and an orientation using latitude, longitude, altitude, and rotation data. 3D models or AR effects can be geo-anchored in the undistorted 3D space in MapillaryJS."),(0,n.kt)("h2",{id:"image"},"Image"),(0,n.kt)("p",null,"The ",(0,n.kt)("a",{parentName:"p",href:"/api/classes/viewer.Image"},"Image")," is the main MapillaryJS entity. An image consists of the texture of a ",(0,n.kt)("a",{parentName:"p",href:"#camera-capture"},"camera capture"),", metadata associated with that camera capture, and artifacts derived from the camera capture itself or the group of adjacent camera captures."),(0,n.kt)("h2",{id:"image-tile"},"Image Tile"),(0,n.kt)("p",null,"2D world maps are divided into tile sets with different level of detail. When zooming to a specific city of the map, higher resolution tiles are loaded and more details appear. In the same way, an image with high resolution can be tiled into smaller pieces. With image tiling it is possible to view every pixel and detail of the original photo without having to load every part of the image at once."),(0,n.kt)("h2",{id:"street-imagery-map"},"Street Imagery Map"),(0,n.kt)("p",null,"A three-dimensional map where the primary navigation and point of view are from the street perspective. The map is visualized through textures and geo-spatial data. MapillaryJS is an example of a street imagery map."),(0,n.kt)("h2",{id:"projection"},"Projection"),(0,n.kt)("p",null,"When talking about projection, we usually refer to the case of an approximated ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Pinhole_camera_model"},"ideal pinhole camera"),". The camera projects coordinates of a point in three-dimensional space onto its image plane. This mapping can be described by the ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Camera_matrix"},"camera matrix"),"."),(0,n.kt)("h3",{id:"types"},"Types"),(0,n.kt)("p",null,"Many different ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/3D_projection"},"projection models")," exist. The once most commonly used with MapillaryJS are ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/3D_projection#Perspective_projection"},"perspective"),", ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Fisheye_lens"},"fisheye"),", and ",(0,n.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Equirectangular_projection"},"spherical")," (or equirectangular) projections."),(0,n.kt)("h2",{id:"unprojection"},"Unprojection"),(0,n.kt)("p",null,"Unprojection is the inverse of ",(0,n.kt)("a",{parentName:"p",href:"#projection"},"projection"),". It is a mapping from points on the two-dimensional image plane to the three-dimensional scene."),(0,n.kt)("h2",{id:"viewer"},"Viewer"),(0,n.kt)("p",null,"The ",(0,n.kt)("a",{parentName:"p",href:"/api/classes/viewer.Viewer"},"Viewer")," object represents the visible, navigable, and interactive imagery component. When you integrate the MapillaryJS street imagery map into your application, you always instantiate a new viewer with a set of options. You use the viewer API to affect the viewer programmatically."),(0,n.kt)("h2",{id:"space"},"Space"),(0,n.kt)("h3",{id:"real-3d-world"},"Real 3D World"),(0,n.kt)("p",null,"The space that we live in. A scene of the real 3D space is captured with cameras when mapping."),(0,n.kt)("h3",{id:"distorted-2d-projection"},"Distorted 2D Projection"),(0,n.kt)("p",null,"The ",(0,n.kt)("a",{parentName:"p",href:"#projection"},"projection")," of the ",(0,n.kt)("a",{parentName:"p",href:"#camera-capture"},"camera captures"),". This is a two-dimensional space, the flat texture. Projection types for images uploaded to Mapillary are generally perspective, fisheye, or equirectangular. All projection types have some distortion. For ",(0,n.kt)("a",{parentName:"p",href:"#perspective"},"perspective")," and ",(0,n.kt)("a",{parentName:"p",href:"#fisheye"},"fisheye")," images it's radial. For ",(0,n.kt)("a",{parentName:"p",href:"#equirectangular"},"equirectangular")," images the distortion comes from the representation itself."),(0,n.kt)("h3",{id:"undistorted-3d-space"},"Undistorted 3D Space"),(0,n.kt)("p",null,"The rendered space in MapillaryJS where textures are undistorted according to their calibration parameters. This space is three-dimensional and its aim is to represent the real 3D world as accurately as possible. In this space, equirectangular (panoramic) images are rendered as spheres."))}d.isMDXComponent=!0}}]);